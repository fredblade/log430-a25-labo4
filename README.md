# Labo 04 â€“ Optimization, Caching, Load Balancing, Test de charge, ObservabilitÃ©

<img src="https://upload.wikimedia.org/wikipedia/commons/2/2a/Ets_quebec_logo.png" width="250">    
Ã‰TS - LOG430 - Architecture logicielle - ChargÃ© de laboratoire: Gabriel C. Ullmann, Automne 2025.

## ğŸ¯ Objectifs d'apprentissage
- Comment configurer Prometheus
- Comment faire un test de charge avec [Locust](https://docs.locust.io/en/stable/what-is-locust.html)
- Comment implÃ©menter le cache avec Redis et le load balancing avec [Nginx](https://nginx.org/en/docs/http/load_balancing.html) pour optimiser la performance

## âš™ï¸ Setup

Dans ce laboratoire, on continuera Ã  utiliser la mÃªme version du Â« store manager Â» dÃ©veloppÃ©e au laboratoire 03, mais nous ferons quelques modifications. Le but n'est pas d'ajouter de nouvelles fonctionnalitÃ©s, mais de mesurer et comparer la performance de lecture/Ã©criture de l'application en utilisant MySQL et Redis. AprÃ¨s avoir mesurÃ© et comparÃ©, nous allons implÃ©menter deux approches d'optimisation : caching et load balancing.

> âš ï¸ **IMPORTANT** : Les documents ARC42 et ADR contenus dans ce dÃ©pÃ´t sont identiques Ã  ceux du laboratoire 03, car nous ne modifions pas l'architecture de l'application dans ce laboratoire.

> ğŸ“ NOTE : Ã€ partir de ce laboratoire, nous vous encourageons Ã  utiliser la bibliothÃ¨que `logging` plutÃ´t que la commande `print`. Bien que `print` fonctionne bien pour le dÃ©bogage, l'utilisation d'un logger est une bonne pratique de dÃ©veloppement logiciel car il offre [plusieurs avantages lorsque notre application entre en production](https://www.geeksforgeeks.org/python/difference-between-logging-and-print-in-python/). Vous trouverez un exemple d'utilisation du `logging` dans `src/stocks/commands/write_stock.py`. Vous trouverez les dÃ©tails de l'implementation d'une classe `logger` dans `src/logger.py`.

### 1. CrÃ©ez un nouveau dÃ©pÃ´t Ã  partir du gabarit et clonez le dÃ©pÃ´t
```bash
git clone https://github.com/[votredepot]/log430-a25-labo4
cd log430-a25-labo4
```

### 2. CrÃ©ez un rÃ©seau Docker
ExÃ©cutez dans votre terminal :
```bash
docker network create labo04-network
```

### 3. PrÃ©parez l'environnement de dÃ©veloppement
Suivez les mÃªmes Ã©tapes que dans le laboratoire dÃ©rnier.

### 4. Installez Postman
Suivez les mÃªmes Ã©tapes que dans le laboratoire dÃ©rnier. Importez la collection disponible dans `/docs/collections`.

### 5. PrÃ©parez lâ€™environnement de dÃ©ploiement et le pipeline CI/CD
Utilisez les mÃªmes approches qui ont Ã©tÃ© abordÃ©es lors des laboratoires dÃ©rniers.

## ğŸ§ª ActivitÃ©s pratiques
Pendant le labo 02, nous avons implÃ©mentÃ© le cache avec Redis. Pendant le labo 03, nous avons utilisÃ© ce cache pour les endpoints des rapports. Dans ce labo, nous allons temporairement dÃ©sactiver le Redis pour mesurer la diffÃ©rence entre les lectures directement de MySQL vs Redis. Pour faciliter les comparaisons, dans ce laboratoire les mÃ©thodes qui font la gÃ©nÃ©ration de rapport dans `queries/read_order.py` ont 2 versions : une pour MySQL, autre pour Redis.

### 1. DÃ©sactivez le cache Redis temporairement
Dans `queries/read_order.py`, remplacez l'appel Ã  `get_highest_spending_users_redis` par `get_highest_spending_users_mysql`. Ã‰galement, remplacez l'appel Ã  `get_best_selling_products_redis` par `get_best_selling_products_mysql`.

### 2. Instrumentez Flask avec Prometheus
Dans `store_manager.py`, ajoutez un endpoint `/metrics`, qui permettra Ã  Prometheus de lire l'Ã©tat des variables que nous voulons observer dans l'application.
```python
@app.route("/metrics")
def metrics():
    return generate_latest(), 200, {"Content-Type": CONTENT_TYPE_LATEST}
```

N'oubliez pas d'ajouter Ã©galement les `imports` suivants:
```python
from prometheus_client import Counter, generate_latest, CONTENT_TYPE_LATEST
```

### 3. CrÃ©ez des Counters 
Ã‰galement dans `store_manager.py`, ajoutez les objets [Counter](https://prometheus.io/docs/concepts/metric_types/#counter) pour compter le nombre de requÃªtes aux endpoints `/orders`, `/orders/reports/highest-spenders` et `/orders/reports/best-sellers`. N'oubliez pas d'appeler la mÃ©thode `inc()` pour incrÃ©menter la valeur du compteur Ã  chaque requÃªte. Par exemple :

```python
counter_orders = Counter('orders', 'Total calls to /orders')
@app.post('/orders')
def post_orders():
    counter_orders.inc()
```

### 4. Observez les mÃ©triques dans Prometheus
Dans Postman, faites quelques requÃªtes Ã  `POST /orders`. Ensuite, accÃ©dez Ã  Prometheus sur `http://localhost:9090` et exÃ©cutez une requÃªte (query) Ã  `orders_total`. Vous devriez voir une valeur numÃ©rique associÃ©e Ã  la variable. Faites la mÃªme chose pour les deux autres `Counters`. Par exemple, si vous avez nommÃ© le compteur `highest_spenders`, exÃ©cutez une requÃªte Ã  `highest_spenders_total`. Cliquez sur `Graph` pour voir la reprÃ©sentation visuelle de chaque variable. Faites quelques requÃªtes de plus pour voir le changement des variables.

> ğŸ“ **NOTE** : Prometheus ne met pas automatiquement Ã  jour les variables dans l'interface Web lorsqu'elles changent dans le serveur. Vous devez cliquer sur `Query` ou recharger la page Web pour voir les valeurs mises Ã  jour.

### 5. Lancez un test de charge avec Locust
Le script `locustfiles/locustfile.py` lorsqu'il est exÃ©cutÃ©, effectuera plusieurs appels vers des endpoints (reprÃ©sentÃ©s par les mÃ©thodes `@task`), simulant ainsi des utilisateurs rÃ©els. Dans un premier temps, nous ne modifierons pas ce script, nous l'activerons simplement Ã  partir de l'interface web Ã  Locust.

AccÃ©dez Ã  `http://localhost:8089` et appliquez la configuration suivante :
- Number of users (nombre d'utilisateurs) : 100
- Spawn rate (taux d'apparition des nouveaux utilisateurs) : 1 (par seconde)

Lancez le test et observez les statistiques et graphiques dans Locust (onglet `Charts`). En un peu moins de 2 minutes, vous devriez observer que votre application reÃ§oit une charge de requÃªtes Ã©quivalente Ã  100 utilisateurs simultanÃ©s.

> ğŸ’¡ **Question 1** : Quelle est la latence moyenne (50Ã¨me percentile) et le taux d'erreur observÃ©s avec 100 utilisateurs ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust (onglet `Charts`).

### 6. Ã‰crivez un nouveau test de charge avec Locust
Dans le rÃ©pertoire `locustfiles/experiments/locustfile_read_write.py`, complÃ©tez le script `locustfile_read_write.py` pour ajouter une commande en utilisant des valeurs alÃ©atoires et une proportion d'exÃ©cution des mÃ©thodes `@task` Ã  66% lectures, 33% Ã©critures (2/3, 1/3, 1/3). Plus d'informations sur la proportion d'exÃ©cution des appels de chaque mÃ©thode `@task` [dans la documentation officielle Ã  Locust](https://docs.locust.io/en/stable/writing-a-locustfile.html#task-decorator).

Finalement, copiez le code modifiÃ© de `locustfiles/experiments/locustfile_read_write.py` Ã  `locustfiles/locustfile.py` et testez-le. Si cela fonctionne, passez Ã  l'activitÃ© 7.

### 7. Augmentez la charge
Augmentez progressivement le nombre d'utilisateurs jusqu'Ã  ce que l'application Ã©choue (timeouts, erreurs 500, etc.).

> ğŸ’¡ **Question 2** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec MySQL) ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

### 8. RÃ©activez Redis
Dans `queries/read_order.py`, remplacez l'appel Ã  `get_highest_spending_users_mysql` par `get_highest_spending_users_redis`. Ã‰galement, remplacez l'appel Ã  `get_best_selling_products_mysql` par `get_best_selling_products_redis`.

### 9. Testez la charge encore une fois
Augmentez progressivement le nombre d'utilisateurs jusqu'Ã  ce que l'application Ã©choue (timeouts, erreurs 500, etc.).

> ğŸ’¡ **Question 3** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec Redis) ? Quelle est la latence et le taux d'erreur observÃ©s ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Locust.

### 10. Testez l'Ã©quilibrage de charge (load balancing) avec Nginx
Pour tester le scÃ©nario suivant, utilisez le rÃ©pertoire `load-balancer-config` :
- Copiez le texte dans `docker-compose-to-copy-paste.txt` et collez-le dans `docker-compose.yml`
- CrÃ©ez un fichier `nginx.conf` dans le rÃ©pertoire racine du projet.
- Copiez le texte dans `nginx-conf-to-copy-paste.txt` et collez-le dans un fichier `nginx.conf`
Observez les modifications apportÃ©es Ã  `docker-compose.yml`. **Reconstruisez le conteneur**, puis redÃ©marrez le conteneur Docker. Relancez ensuite les tests avec Locust (mÃªmes tests de l'activitÃ© 9).

> ğŸ’¡ **Question 4** : Ã€ partir de combien d'utilisateurs votre application cesse-t-elle de rÃ©pondre correctement (avec Redis + Nginx load balancing) ? Quelle est la latence et le taux d'erreur observÃ©s ? Cela et une amÃ©lioration par rapport au scÃ©nario de l'activitÃ© 7 ? Illustrez votre rÃ©ponse Ã  l'aide des graphiques Prometheus (onglet `Graph`).

> ğŸ’¡ **Question 5** : Dans le fichier `nginx.conf`, il existe un attribut qui configure l'Ã©quilibrage de charge. Quelle politique d'Ã©quilibrage de charge utilisons-nous actuellement ? Consultez la documentation officielle Nginx si vous avez des questions.

## ğŸ“¦ Livrables

- Un fichier .zip contenant l'intÃ©gralitÃ© du code source du projet Labo 04.
- Un rapport en .pdf rÃ©pondant aux questions prÃ©sentÃ©es dans ce document. Il est obligatoire d'illustrer vos rÃ©ponses avec du code ou des captures d'Ã©cran/terminal.